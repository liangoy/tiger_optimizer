## Tiger
tiger optimizer for tiger

## feature
This implementation method if tiger can help you to avoid round-off error if abs(parameter)/1000 > learning_rate * abs(gradient)  so that you can trainning one both float16 parameter and float16 gradient


## Citation
@misc{su2023tiger,
  title     = {Tiger: A Tight-fisted Optimizer},
  author    = {Jianlin Su},
  year      = {2023},
  howpublished = {\url{https://github.com/bojone/tiger}}
}
